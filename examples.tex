\section{Learning by example}\label{S:examples}

We begin with an extended example comparing two proofs of different systems in
different verification environments (Section~\ref{S:ex_ext}). We then briefly
discuss a few other examples (Section~\ref{S:ex_notable}) and point towards a
plethora of other verified programs research (Section~\ref{S:ex_reading}).

\subsection{Extended example: distributed hash tables and regular
expressions}\label{S:ex_ext}

We have previously written two proofs of sufficient size and complexity that
their study will demonstrate both common proof techniques and challenges. We will
not provide all the details, in part because both were completed for academic
exercises and We wish to avoid publishing full solutions, and in part because
some details are not relevant for the discussion here (proof scripts and
programs available on request). It is important to note that in one case, there
is no final executable program; rather, the proof is written entirely in a
relational style. This facilitates the proof at the cost of not having a program
to run. A final step would be to implement the full programs and prove its
agreement with the relational definition.

The first proof is that a (somewhat idealized) distributed hash table behaves
like a logically centralized hash table; this was modeled and proved in
Dafny~\cite{leino2010dafny} for the 2020 Systems Software Verification Summer
School~\cite{Kapritsos_2020}. We defer details on hash tables to classic texts
like~\cite{CLRS}. This proof has no final executable.

The second proof is that a regular expression matching algorithm based on
derivatives is correct with respect to the theory of regular expressions. This
was modeled and proved in Coq~\cite{Coq} for a course using the \emph{Logical
Foundations} text~\cite{Pierce:SF1}. Details on regular expressions may be found
in~\cite{Lewis_1997,Morrisett_2012}; details on the derivatives of regular
expressions, also used in~\cite{Pierce:SF1,Morrisett_2012}, can be found
in~\cite{Might_Yacc,Might_desugar,Might_deriv}. This proof does define a
matching function that can be extracted to OCaml, Haskell, or Scheme;
see~\cite{Coq_Extract} or~\cite[Extraction]{Pierce:SF1} for details.

We present the examples by following the chronology of their development. First,
we develop a model of the theory (Section~\ref{S:ex_theory}). Second, we model
the program to be verified (Section~\ref{S:ex_program}). Third, we write down
the formal specification (Section~\ref{S:ex_spec}). Finally, we sketch a proof
by induction that the models implement the specification
(Section~\ref{S:ex_ind}).

\subsubsection{Model of the theory}\label{S:ex_theory}

Here we develop the necessary theories of hash tables and regular expressions.
They will be needed especially for the formal specification
(Section~\ref{S:ex_spec}) and proof (Section~\ref{S:ex_ind}).

\paragraph{Hash table.} Our theory of hash tables is to use a full Dafny map,
specifically an infinite map from integers to integers. This means every
possible integer key maps to a value; the default is 0. We specify two
relations: the initial state and the possible transitions. This gives us an
inductive state machine to describe hash tables. The initial state is all keys
map to 0. The possible transitions are the relations \(\func{Get}\) and
\(\func{Put}\), each of which relate a current state to the next state. Recall
that \(\definedas\) indicates a definition. We use the standard map-update
notation \(M[k \gets v]\) to represent the map \(M\) with \(k\) now mapped to
\(v\).

\begin{align*}
    \func{Get}(\var{state}, \var{state'}, \var{key}, \var{value}) \definedas\;&
    \var{state}[\var{key}] = \var{value} \\
    & \land \var{state'} = \var{state} \\
    \\
    \func{Put}(\var{state}, \var{state'}, \var{key}, \var{value}) \definedas\;&
    \var{state'} = \var{state}[key \gets value].
\end{align*}

Note that the \(\func{Get}\) relation asserts that the state is unchanged; this
property will show up later in other models and is crucial to correctness.
Without this statement, \(\var{state'}\) could be any possible state after a get
operation is performed.

In Dafny, we also define
\begin{inlist}
\item a sum-type Step capturing the non-stateful parameters of the transitions
    (here, \(\func{GetStep}\) and \(\func{PutStep}\) capture a key-value pair
    for the \(\func{Get}\) and \(\func{Put}\) relations) and
\item a relation \(\func{Next}\) that asserts the existence of some
    \(\func{Step}\) value such the corresponding transition relation holds.
\end{inlist}

The key takeaway is the modelling of the problem domain via an inductive state
machine and relations (or predicates) between possible states. Dafny does not
connect the relations automatically; that is, there is no indication that the
initial state predicate and the \(\func{Next}\) predicate form an induction
principle. We would need to write a meta-theoretical proof to connect the
predicates to induction, but we can still structure the remaining proofs
inductively and be confident in their correctness.

\paragraph{Regular Expressions.} Coq supports the type of inductive relations
used for hash tables; for the theory of regular expressions we will define what a
regular expression is and how a string matches one. We define an inductive
datatype \(\func{regexp}\), parameterized on the type \(T\) of strings, with the
usual alternatives. Below, \(\epsilon\) is the regular expression for the empty
string, not to be confused with the empty regular expression \(\emptyset\),
which matches no strings.

\begin{align*}
    \func{regexp}(T) \definedas\;
    & |\; \emptyset \\
    & |\; \epsilon \\
    & |\; \func{Char}(t: T) \\
    & |\; \func{App}(\var{left}: \func{regexp}(T), \var{right}: \func{regexp}(T)) \\
    & |\; \func{Union}(\var{left}: \func{regexp}(T), \var{right}: \func{regexp}(T)) \\
    & |\; \func{Star}(\var{re}: \func{regexp}(T)).
\end{align*}

We also need a theory of ``matching'': what does it mean for a string to match a
regular expression? We write \(s \matches r\) for the assertion that a string
\(s\) is a list of \(T\)s matching a regular expression \(r\) over the type
\(T\). At this point, there are several options. We could use a reference
implementation and prove that out derivative matcher is equivalent; this
requires that we have a reference implementation, and it still needs to be
verified. We could construct finite automata and write proofs about graphs;
according to~\cite{Morrisett_2012} graphs are unwieldy in Coq. Instead, we will
stick with induction and define the rules for matching as an inductive
proposition. We write \(s_1 \texttt{++} s_2\) for string concatenation.

\begin{mathparpagebreakable}
    \inference[\iname{MEmpty}]{}{[] \matches \epsilon}
    \and
    \inference[\iname{MChar}]{}{[x] \matches \func{Char}(x)}
    \and
    \inference[\iname{MApp}]{s_1 \matches r_1 & s_2 \matches r_2}
    {s_1 \texttt{++} s_2 \matches \func{App}(r_1, r_2)}
    \and
    \inference[\iname{MUnionL}]{s_1 \matches r_1}{s_1 \matches \func{Union}(r_1, r_2)}
    \and
    \inference[\iname{MUnionR}]{s_1 \matches r_2}{s_1 \matches \func{Union}(r_1, r_2)}
    \and
    \inference[\iname{MStar0}]{}{[] \matches \func{Star}(r)}
    \and
    \inference[\iname{MStarApp}]{s_1 \matches r & s_2 \matches \func{Star}(r)}
    {s_1 \texttt{++} s_2 \matches \func{Star}(r)}.
\end{mathparpagebreakable}

Because these are inductive definitions, Coq automatically generates induction
principles for use in proofs. Thus we define the problem-domain inductively,
again.

These definitions can be read analogously to the relational predicates
describing transitions in the hash table state machine. We can use these rules
to construct proofs that a string matches a regular expression; the only way to
extend these rules is to prove a theorem about the matching relation. Because
Coq is constructive, such a proof will necessarily involve the use of these
rules or another such theorem---unfolded, all proofs about \(\matches\) are built
on these rules and the standard rules of Coq's logic.

The inductive construction turns out to be a good pattern for verified programs;
only the simplest programs make use of purely finite types (\eg, booleans) and
can be verified with a finite case analysis. Most interesting programs require
reasoning by induction to handle the infinite.

\subsubsection{Model of the program}\label{S:ex_program}

Here we develop programs for distributed hash table communication and
regular expression matching. It is these programs that we wish to prove
implement specifications of the above theories.

\paragraph{Distributed Hash table.} We need a number of definitions to represent
the network and hosts that will communicate. We begin by axiomatizing the number
of hosts to be some fixed but unknown \(n\) and gathering the set of ids where
\(0 \le id < n\). Next, we model the network: in its idealized representation, it
sends messages only once. The network is \emph{also} an inductive state machine;
each step consists of an \(\func{Action}\) representing an optional message for
a host to receive, which must have been sent, and a set of messages to be
delivered in the future. We then abstractly model a distributed system in this
network: the system requires definitions for the message and host types, as well
as inductive state machine predicates for the host (\(\func{HostInit}\) and
\(\func{HostNext}\)). Each host is told its id by the distributed system. It
then collects a map of all ids to hosts and generalizes the host state machine
as follows: the initial state of the system is that each host and the network is
initialized. The transition is taken by only a single host at a time, in
lock-step with the network; that is, the abstract system's \(\func{Next}\)
predicate keeps all hosts but one the same---that host is given to
\(\func{HostNext}\), and the network to the corresponding \(\func{NetNext}\).
Finally, to conclude the program, we define a host for use in the distributed
hash table and instantiate the abstract distributed system accordingly. Host 0
starts with the entire hash table (all keys mapped to 0). The other hosts are
empty. The predicates and types for \(\func{HostNext}\) incorporate a network
\(\func{Action}\); the possibilities include updated versions of \(\func{Get}\)
and \(\func{Put}\):

\begin{alignat*}{2}
    & \func{Get}(\var{state}, \var{state'}, \var{action}, \var{key}, \var{value}) \definedas\; \\
    & \var{key} \in \var{state} && \text{Host can only get keys in its table} \\
    & \land \var{state}[\var{key}] = \var{value} \\
    & \land \var{state'} = \var{state} \\
    & \land \var{action.receive} = \func{None} && \text{No messages received} \\
    & \land \var{action.send} = \emptyset && \text{No messages sent} \\
    \\
    & \func{Put}(\var{state}, \var{state'}, \var{key}, \var{value}) \definedas\; \\
    & \var{key} \in \var{state} && \text{Host can only update keys in its table} \\
    & \land \var{state'} = \var{state}[\var{key} \gets \var{value}] \\
    & \land \var{action.receive} = \func{None} && \text{No messages received} \\
    & \land \var{action.send} = \emptyset && \text{No messages sent.}
\end{alignat*}

In order for the distributed system to do anything interesting, we also include
the ability to send and receive hash tables. Note that in \(\func{Receive}\) the
receiving host will prefer its own key-value pair to one in the message when the
keys are the same (\ie, in case of conflict, the recipient takes precedence).

\begin{alignat*}{2}
    & \func{Send}(\var{state}, \var{state'}, \var{action}, \var{message}) \definedas\; \\
    & \var{action.send} = \set{\var{message}} && \text{Host sends a message} \\
    & \land \var{action.receive} = \func{None} && \text{No messages received} \\
    & \land \var{message} \subseteq \var{state} && \text{Message is subset of host's table} \\
    & \land \forall \var{k} \in \var{message} : \\
    & \qquad \var{message}[\var{k}] = \var{state}[\var{k}]
        && \text{Message agrees with host's values} \\
    & \land \var{state'} = \var{state} \setminus \var{message}
        && \text{Host removes sent key-value pairs}\\
    \\
    & \func{Receive}(\var{state}, \var{state'}, \var{action}) \definedas\; \\
    & \var{action.send} = \emptyset && \text{No messages sent} \\
    & \land \var{action.receive} = \func{Some}(\var{table})
        && \text{Host receives message with table} \\
    & \land \var{state'} = \var{state} \uplus \var{table}
        && \text{Host updates key-value pairs.}
\end{alignat*}

The key take-away is that this model of the program follows a suitably similar
inductive state machine relation as that of the original hash table. The key
differences are network and distributed system abstractions and their
incorporation into the host state machine. The use of abstract models makes the
model more reusable and enables layering---proofs about low-level systems can be
easily composed with proofs about the high-level via refinement, which we will
discuss in Section~\ref{S:ex_spec}. We say that the distributed hash table model
\emph{refines} the distributed system model.

\paragraph{Regular Expressions.} Following the theory of derivatives of regular
expressions, we are interested in a regular expression matching function that
correctly tests whether or not a string matches a regular expression.

The result of the derivative \(D_a(r)\) is a regular expression that matches all
words that \(r\) matched without the leading \(a\). We can write this in the
language of formal languages, using \(a + w\) for the character \(a\) prepended
to the string \(w\):

\begin{equation*}
    \mc{L}(D_a(r)) = \setbuild{w}{a + w \in \mc{L}(r)}.
\end{equation*}

To write a matching function with derivatives is to continuously take the
regular expression's derivative with respect to the characters in the string;
only if the final expression matches the empty string is the result considered a
match. More details on the algorithm and definitions are
in~\cite{Might_Yacc,Might_desugar,Might_deriv}. To formalize these definitions
in Coq, we write three recursive functions that compute a fix-point. The first
tests whether or not a regular expression matches the empty string in the
obvious way:

\begin{align*}
    \func{Empty}(\emptyset) &= \false \\
    \func{Empty}(\epsilon) &= \true \\
    \func{Empty}(\func{Char}(\_)) &= \false \\
    \func{Empty}(\func{App}(\var{left}, \var{right})) &=
        \func{Empty}(\var{left}) \text{ and } \func{Empty}(\var{right}) \\
    \func{Empty}(\func{Union}(\var{left}, \var{right})) &=
        \func{Empty}(\var{left}) \text{ or } \func{Empty}(\var{right}) \\
    \func{Empty}(\func{Star}(\_)) &= \true.
\end{align*}

The second computes the derivative of a regular expression with respect to a
particular character; the only non-obvious rule is for \(\func{App}\), where we
must carefully consider whether or not \(\var{left}\) can match an empty string:

\begin{align*}
    \func{D}_a(\emptyset) &= \emptyset \\
    \func{D}_a(\epsilon) &= \emptyset \\
    \func{D}_a(\func{Char}(c)) &= \begin{cases}
        \epsilon & a = c \\
        \emptyset & a \neq c
    \end{cases} \\
    \func{D}_a(\func{App}(\var{left}, \var{right})) &= \begin{cases}
        \func{Union}(\func{App}(\func{D}_a(\var{left}), \var{right}),
                     \func{D}_a(\var{right})) & \func{Empty}(\var{left}) \\
        \func{Union}(\func{App}(\func{D}_a(\var{left}), \var{right}),
                     \emptyset) & \text{otherwise}
    \end{cases} \\
    \func{D}_a(\func{Union}(\var{left}, \var{right})) &=
        \func{Union}(\func{D}_a(\var{left}), \func{D}_a(\var{right})) \\
    \func{D}_a(\func{Star}(r)) &= \func{App}(\func{D}_a(r), \func{Star}(r)).
\end{align*}

The third implements our matching algorithm:

\begin{align*}
    \func{Match}([], r) &= \func{Empty}(r) \\
    \func{Match}(a+w, r) &= \func{Match}(w, \func{D}_a(r))
\end{align*}

It may not appear that we used inductive definitions to model our regular
expression matching program, but the close relationship between recursive
functions and induction hints at the nature of our program. Indeed, as we have
already stated, the equivalence proofs will all be by induction. Pay attention
to the inductive structure of the functions: \(\func{Empty}\) and \(\func{D}\)
are recursive on the regular expression; in contrast, \(\func{Match}\) is
recursive on the string. This is a strong clue for the proof-writer about the
direction to take in the actual proof.

The two programs are noticeably different: in one, we define another
state machine in terms of relations between states. In the other, we provide
computable functions over data. Yet the proofs will have striking similarities.
Besides the key difference of executability, there is also a difference in
abstraction level. The hash table example models an idealized network and an
abstract distributed system instantiated with a particular protocol for host
communication. The regular expression example is abstract only in the type of
characters in the string with the restriction that equality of two characters
must be decidable. In addition, the hash table example lacks any formalizations
relating the initial and next predicates; they are designed to form an induction
principle\footnote{For a introductory treatment of induction principles in Coq,
see~\cite[Induction Principles]{Pierce:SF1}}, but a meta-theoretic proof is
needed to show that they are. The regular expression program needs no induction
principles; they are already provided by the regular expression type and the
definition of the matches relation.

\subsubsection{Formal specification}\label{S:ex_spec}

In this section we discuss the specification the two programs must meet, first
informally and then formally.

\paragraph{Hash table.} Informally, we would like the distributed hash table
state machines to behave collectively like the state machine for a single hash
table. As a first try, we might want the states to be equivalent step for step.
That is, each step in the single hash table should correspond to a step in the
distributed system. For this, we need a function that maps the distributed
system state into the state of a single hash-table; the simplest version is to
collect all the maps in the system, union them together, and then guarantee the
resulting map is full by returning the all-zero map in the case that it is not
full. A correct implementation will need to avoid falling in to the all-zero map
case by maintaining a full map across all the hosts---this is so that a
\(\func{Put}\) step in the single hash table is accurately reflected in the
distributed system and \emph{vice-versa}.

There is a subtle problem with the strict equivalence above: notice that, if the
program is correct, \(\func{Send}\) and \(\func{Receive}\) in the distributed
system should not change the overall state of the collective key-value pairs.
There is no corresponding state change in the single hash table. To overcome
this challenge, we introduce the notion of a \emph{stutter step}. This is a faux
state change wherein the state is actually unchanged. The actual
correctness criterion is that whenever the distributed system takes a step via
its \(\func{Next}\) predicate, the single hash table either also takes a step or
remains the same (a stutter step).

We formalize this in two proof obligations, or theorems, about the program. Let
the function \(I\) be an interpretation function mapping distributed system
state into single hash-table state. The theorems resemble the two stages of
induction: a base case (Theorem~\ref{Th:h_init}) and an inductive case
(Theorem~\ref{Th:h_ind}). In inductive proofs, we wish to prove some proposition
\(P\) for all possible elements. Thus the programmer supplies \(P\) as a
predicate \(\func{Inv}\) that is maintained by their program. The goal is for
\(\func{Inv}\) to imply the desired safety or correctness properties; it is also
allowed to contain other additional invariants. In many cases these additional
invariants are necessary to correctness.

Below, we will use the subscript \(D\) to represent functions and propositions
about the distributed system, and \(S\) for the same about the single hash
table.

\begin{thm}[Initial state correctness]\label{Th:h_init}
    For all distributed system states \(s\), we have
    \begin{align*}
        \func{Init}_{D}(s) \implies \\
        \func{Inv}(s) \land \func{Init}_{S}(I(s)).
    \end{align*}
\end{thm}

\begin{thm}[Inductive state correctness]\label{Th:h_ind}
    For all distributed system states \(s, s'\), we have
    \begin{align*}
        \func{Inv}(s) \land \func{Next}_{D}(s, s') \implies \\
        \func{Inv}(s') \land (\func{Next}_{S}(I(s), I(s')) \lor I(s) = I(s')).
    \end{align*}
\end{thm}

Notice that we still need a meta-theoretic proof that for all propositions \(P\)
about the distributed system state, Theorems~\ref{Th:h_init} and~\ref{Th:h_ind}
imply that \(P\) holds for all state. That is, we haven't formalized the
induction principle at play here.

\begin{rem}
    Hiding behind the \(D\) subscript is the network: the collection of tables
    in the distributed system is not limited to all the tables currently on the
    hosts. It must also include any tables that ``in transit'' on the network!
    Otherwise keys might temporarily ``disappear,'' causing them to be lost. We
    would not be able to finish the proof if we ignored the network in our
    interpretation function \(I\).
\end{rem}

Specifying the invariant correctly for Dafny often involves an educated guess:
start with the direct correctness or safety conditions, and then add needed
information as you discover that you need it during the inductive process. Here,
the critical properties are that all the tables at each host are disjoint (so
that each key is owned by exactly one node) and that the overall collection of
host state is a full table (so that no keys have disappeared).

One challenge in a system like Dafny is that we must make the structure of our
proof explicit in the specification: we are clearly proceeding with a proof that
resembles induction. A unique takeaway from this particular problem is the
pairing of state machine transitions to prove that the observable behavior is
the same. This style of proof is especially relevant for proofs about large
classes of programs, like for verified compilers. We'll see an example in
Section~\ref{S:ex_notable}.

\paragraph{Regular Expressions.} Informally, we need \(\func{Match}\) to
correctly implement matching; that is, \(\func{Match}(s, r)\) should be
\(\true\) whenever \(s \matches r\). But \(\func{Match}\) is a (decidable)
boolean and the matches relation is a proposition, which is, in general,
undecidable. The two are not directly compatible with connectives like \(\iff\);
that is, we cannot write \(\forall s, r: \func{Match}(s, r) \iff s \matches r\)
as our specification. We could instead use the proposition \(\func{Match}(s, r) =
\true\), but we choose to use a technique called ``proof by reflection.'' The
idea is that some propositions are in fact decidable; as a witness, we provide a
predicate that computes the truth value. The predicate is said to \emph{reflect}
the proposition. We will write \(b \reflects P\) in these cases; note that
implicitly \(\neg b \reflects \neg P\). To prove such a claim, we must show that
in each possible case of the computation of \(b\), the proposition \(P\) is
provable or derives a contradiction. We are able to make use of the (proved)
fact that \(b \reflects P \equiv b = true \iff P\). Proof by reflection is a
common and powerful technique for relating predicates to propositions and for
doing case-analysis over propositions in logics without the law of excluded
middle\footnote{The LEM states \(\forall P, P \lor \neg P\). This is not assumed
by Coq as Coq uses a constructive logic. It is possible to add the axiom;
however, this has the effect of changing the logic in a subtle way.}. The rules
of reflection are succinctly stated:
\begin{mathpar}
    \inference[\iname{Reflect-T}]{P}{\true \reflects P} \and
    \inference[\iname{Reflect-F}]{\neg P}{\false \reflects P}
\end{mathpar}
With a reflection relation proven, we can analyze the two cases: either the
witness function computes true or false. In addition, we are given information
about \(P\) or \(\neg P\) which we can use to reason with the usual connectives
and tactics.

Thus we state our proof obligation:
\begin{thm}[Match correctness]\label{Th:r_match}
    For all strings \(s\) and regular expressions \(r\), we have
    \(\func{Match}(s, r) \reflects s \matches r\).
\end{thm}

As we will see, we will also need correctness for the other two functions. The
correctness theorem for \(\func{Empty}\) is simple:
\begin{lem}[Empty correctness]\label{Lem:r_empty}
    For all regular expressions \(r\), we have \\
    \(\func{Empty}(r) \reflects [] \matches r\).
\end{lem}

For the derivative, we need to formalize what it means to be a derivative. We
define the relation \(\Delta\) between two regular expressions \(r\) and \(r'\)
with respect to character \(a\) as for all strings \(s\), \(a+s \matches r \iff
s \matches r'\). That is, \(\Delta(r, a, r')\) is provable exactly when \(r'\)
is the derivative of \(r\) with respect to \(a\). Then the correctness theorem
for \(\func{D}\) is stated as:
\begin{lem}[Derivative correctness]\label{Lem:r_derive}
    For all characters \(a\) and regular expressions \(r\), we have
    \(\Delta(r, a, \func{D}_a(r))\).
\end{lem}

In this example we also need auxiliary correctness statements; we will see
analogues in the hash-table proof. The difference is that, from our development
of the \(\func{Match}\) function, we know we need \(\func{Empty}\) and
\(\func{D}\) to be correct. In the hash table case, we have hidden some of the
analogous functions in notation---we end up needing information about table
union and removal, fullness, disjointness, and the location of tables in order
to complete the proof.

\subsubsection{Proof by induction}\label{S:ex_ind}

Finally we come to the proofs. We will omit the details and focus on a few key
ideas.

In the case of the hash table proof, we are interested in the following: first,
Dafny can automatically prove some lemmas and fill in some details in theorems.
This avoids some tedium, at the cost of hiding the exact proof state. Second,
proof development in Dafny follows a sort of 20-questions style. Lastly, Dafny
suffers from a ``timeout demon'' due to the use of an \gls{smt} solver. This
leads to some challenges in large proof developments.

In the case of regular expressions, we are interested in the following: first,
there is a clever technique to simplify the reflection proof. We relate the
\(\matches\) judgements to propositions involving the usual connectives. As a
challenge, however, Coq struggles to apply theorems under existential
quantifiers. Second, though not used to its full extent in our proof script, Coq
allows expressive proof-automation, albeit not as automatically as Dafny. Third,
the Coq proof is entirely interactive, so that we know exactly what context we
are in and what the goals are at any time. This can make it easier to reason
about complex state, as we are not guessing what the state looks like.

\paragraph{Hash table.} Looking at our two proof obligations,
Theorem~\ref{Th:h_init} seems the easier of the two: we need to prove that
\(\func{Init}_{D}\) is correct with respect to \(\func{Init}_{S}\) and that it
establishes the invariants (disjointness and fullness). After we write the
statement of the theorem, Dafny asks for a proof. We first let it attempt to
fill in the details, leaving the body blank; Dafny complains that the two
post-conditions (correctness and the invariants) may not hold. This is Dafny's
way of telling us that it cannot work out all the details. By examining the
definition of \(\func{Init}_{S}\), we know we need to first show that \(I\) maps
the initial distributed state to the initial single state. Logically, we know
that one host contains the full 0-table, and the other hosts' tables are empty,
so they shouldn't contribute to the result. We also know there is nothing on the
network. We ask Dafny: if we can prove these few facts, will you believe
correctness of \(\func{Init}\)? To do so, we \texttt{assert} the following facts
without proof:
\begin{itemize}
    \item the host with id 0 contains a table mapping all keys to 0;
    \item any host with id not 0 contains an empty table;
    \item the table-union of a non-empty table and any number of other empty
        tables is the non-empty table;
    \item there are no messages on the network; and therefore
    \item \(I\) maps the initial distributed state to the initial single state
        by considering a table-union of a single full 0-table with empty tables.
\end{itemize}
Indeed, at this point, Dafny no longer complains that the \(\func{Init}_{S}\)
post-condition cannot be established. However, it does flag some (not all!) of
the assertions as not established. In other words, if we can prove the remaining
assertions, we will have successfully given Dafny enough to finish part of the
proof. Dafny observes on its own all of the facts except that empty tables do
not contribute to a table-union. We state this as a separate lemma and play
another round of 20-questions with Dafny: what will it take to convince you?
Briefly, we are able to complete the proof via an inductive structure that
mimics the recursive nature of the table-union function---we invoke the lemma we
are proving in the recursive case, much like a recursive function call. An
important auxiliary lemma in the proof is that the table-union of empty tables
is also empty: this has no proof body, for Dafny can observe its truth entirely
automatically. We still need to show the invariants, but fullness follows from
the establishment of \(\func{Init}_{S}\), and the tables are also clearly
disjoint by similar reasoning; Dafny fills in most of these details.

The proof of Theorem~\ref{Th:h_ind} is similar in many respects: we ask Dafny if
it can prove the required definitions automatically; where it cannot, we start
unfolding definitions and \texttt{assert}ing facts until Dafny has enough
information. Then, we supply proofs for the assertions. We also have to reason
by case-analysis on the possible steps for the distributed system (recall from
Section~\ref{S:ex_program} the steps \(\func{Get}\), \(\func{Put}\),
\(\func{Send}\), and \(\func{Receive}\)). Some cases require more details then
others; we wind up needing auxiliary statements like ``if all the tables are
disjoint, then the table that owns the key controls the value that the key maps
to in the table-union'' and ``the invariants disjointness and fullness imply
that the union is also full'' (both of which Dafny fills in almost
automatically). Similarly, with little assistance Dafny can see that a
\(\func{Put}\) step keeps full maps full. However, as the proof starts to get
larger, and the more complicated details are filled in, Dafny's checker gets
slower and slower. It eventually grinds to a halt---we, the programmers, are
left with a tool that should be mostly automatic but has effectively stopped its
dialogue with us. What went wrong?

By limiting the time spent per proof, we identify that we are stuck in Dafny's
``timeout demon.'' A full tutorial on profiling Dafny execution to identify the
source of the timeout is out of scope; see
\citeauthor{Kapritsos_2020}~\cite{Kapritsos_2020} for details. The source of the
demon is related to the way Dafny and its underlying engine and solver unfold
definitions and attempt to use them. In this case, two different definitions
make trouble: disjointness and fullness. Let's examine their definitions:
\begin{align*}
    \func{Disjoint}(\var{tables}) &\definedas \forall t_1, t_2 \in \var{tables}:
    t_1 \neq t_2 \implies \func{Keys}(t_1) \intersect \func{Keys}(t_2) = \emptyset
    \\ \text{and} \\
    \func{Full}(\var{tables}) &\definedas \forall \var{key} : \exists t \in
    \var{tables} : \var{key} \in t.
\end{align*}
In the case of disjointness, Dafny might try to apply the definition anywhere
there are tables to make progress; unfortunately, there are lots of tables in
the proofs, so this leads to an explosion of applications that make little
progress. In the case of fullness, Dafny struggles to resolve the
universal-existential pair, leading to similar explosions or slowdowns. The
resolution in both cases is to mark the definitions \texttt{\{:opaque\}}, an
annotation that prevents Dafny from unfolding the definitions except when
explicitly \texttt{reveal}ed---this gives the programmer more control over the
scope of the definitions, but closes off an avenue of automation. Now, we have to
rework previously acceptable proofs to reveal definitions at the key steps so
that Dafny can see we have satisfied them. When filling in these details, as
before, we are not shown the exact proof state, and have to continue parts of the
20-questions game.

This concludes our short tour of Dafny via distributed hash tables. We saw how
to model inductive state machines for both theoretical and practical models, how
to state correctness criteria for an inductive proposition, and how to use
Dafny's auto-active features to assist proof-development. We also saw the cost
of that auto-activity in the ``timeout demon'' and the lack of visible context.

\paragraph{Regular Expressions.} Let's first examine the proof of
\(\func{Match}\) correctness. Lemmas~\ref{Lem:r_empty} and~\ref{Lem:r_derive}
make the proof of Theorem~\ref{Th:r_match} straightforward; we proceed by
induction on the string \(s\), since \(\func{Match}\) recurs on it. The
correctness of \(\func{Empty}\) demonstrates the base case (\(s = []\)). In the
inductive case (\(s = x + w\)), we can use the induction hypothesis on the
derivative of the regular expression with respect to \(x\). This, combined with
\(\func{D}\) correctness, is enough to finish the proof.

The proofs of our two lemmas actually hide much of the detail of the final
proof. They also proceed by induction, but on a regular expression. In order to
make use of the statements about \(\matches\) that the induction hypothesis
gives us, we would like to reason with more traditional logical connectives.
Thus we first prove a series of lemmas connecting the inference rules (\eg,
\iname{MUnionL}, \iname{MStar0}) and regular expression constructors (\eg,
\(\func{Union}\), \(\func{Star}\)) to more natural propositions. As an example,
it is straightforward to show that
\begin{equation*}
    \forall s, \var{left}, \var{right}:
    s \matches \func{Union}(\var{left}, \var{right})
    \iff
    s \matches \var{left} \lor s \matches \var{right}.
\end{equation*}
We often need to show these statements by induction, but the only interesting
cases are when the overall regular expression is of the type we care about. With
Coq's automation\footnote{A full overview is out of scope. The Coq manual,
accessible from the Coq homepage~\cite{Coq}, explains how to use the automation
language Ltac as well as automation tacticals.} we can automatically discard
all the other cases and focus on just the details of the particular case (this
is particular useful in the cases for \(\func{Star}\)).

These propositions end up being more amenable to use with the induction
hypotheses. However, we run into trouble with \(\func{App}\) and
\(\func{Star}\). Their logical equivalents involve the use of the existential
quantifier; Coq's constructive logic requires us to give a witness to complete
the proof. As an example, we give the lemma for \(\func{App}\) with a non-empty
string.
% \begin{lem}
%     For all strings \(s\) and regular expressions \(\var{left}, \var{right}\),
%     we have
%     \begin{mathpar}
%         s \matches \func{App}(\var{left}, \var{right}) \\
%         \iff \\
%         \exists s_0, s_1: s = s_0 \texttt{++} s_1 \land s_0 \matches \var{left} \land s_1 \matches \var{right}
%     \end{mathpar}
% \end{lem}
\begin{lem}
    For all strings \(a + s\) and regular expressions \(\var{left}, \var{right}\),
    we have
    \begin{mathpar}
        a + s \matches \func{App}(\var{left}, \var{right}) \\
        \iff \\
        [] \matches \var{left} \land a + s \matches \var{right} \\
        \lor \\
        \exists s_0, s_1: s = s_0 \texttt{++} s_1 \land a + s_0 \matches \var{left} \land s_1 \matches \var{right}
    \end{mathpar}
\end{lem}
% \begin{lem}
%     For all strings \(a + s\) and regular expressions \(r\), we have
%     \begin{mathpar}
%         a + s \matches \func{Star}(r) \\
%         \iff \\
%         \exists s_0, s_1: s = s_0 \texttt{++} s_1 \land s_0 \matches r \land s_1 \matches \func{Star}(r)
%     \end{mathpar}
% \end{lem}
This prevents us from performing certain obvious rewrites that in
other situations would make the proof simpler. The issue is further demonstrated
in the excerpts in \figurename~\ref{F:r_derive}.

\begin{figure}[ht]
\begin{verbatim}
4 subgoals
(2 unfocused at this level)

re1, re2 : reg_exp ascii
IHre1 : forall (s : list ascii) (a : ascii),
        a :: s =~ re1 <-> s =~ derive a re1
IHre2 : forall (s : list ascii) (a : ascii),
        a :: s =~ re2 <-> s =~ derive a re2
s : list ascii
a : ascii
H : ([ ] =~ re1) /\ s =~ derive a re2

========================= (1 / 4)

(exists s0 s1 : list ascii, s = s0 ++ s1
                        /\ (s0 =~ derive a re1) /\ s1 =~ re2)
\/ s =~ (if match_eps re1 then derive a re2 else EmptySet)

========================= (2 / 4)

(exists s0 s1 : list ascii, s = s0 ++ s1
                        /\ (s0 =~ derive a re1) /\ s1 =~ re2)
\/ s =~ (if match_eps re1 then derive a re2 else EmptySet)
\end{verbatim}
    \caption{Selected output from the interactive proof of
    Lemma~\ref{Lem:r_derive}. Subgoals 3 and 4 are elided.}\label{F:r_derive}
\end{figure}

One useful feature of Coq, particularly in the proof of correctness of
\(\func{D}\), is the interactive state. As a rather verbose example that also
demonstrates the rewrite-under-existential issue above, we show a sample from the
correctness proof of \(\func{D}\) in the \(\func{App}\) case in
\figurename~\ref{F:r_derive}. Note how Coq shows the goals to prove and the
hypotheses and variables in the current context. One might wish to use
\texttt{IHre1} in a few of the goals, but the relevant terms are stuck under
\texttt{exists}. In this state, we can focus on a particular subgoal and its
associated context and see explicitly all of the proof state.

In the first goal, for example, we can proceed on the cases of our
\(\func{Empty}\) reflection lemma: either \(\func{Empty}(\var{re_1})\) is true
and the conditional collapses to \(s \matches \func{D}_a(\var{re_2})\), in which
case the right side of the disjunct follows by the right side of the conjunct
\texttt{H}; or, we have a contradiction, since by the left side of \texttt{H} we have \([]
\matches \var{re_1}\) but case analysis said \([] \not\matches \var{re_1}\)
since \(\func{Empty}(\var{re_1})\) is false.

\begin{figure}[ht]
\begin{verbatim}
1 subgoal
(2 unfocused at this level)

re1, re2 : reg_exp ascii
IHre1 : forall (s : list ascii) (a : ascii),
        a :: s =~ re1 <-> s =~ derive a re1
IHre2 : forall (s : list ascii) (a : ascii),
        a :: s =~ re2 <-> s =~ derive a re2
s : list ascii
a : ascii
H : exists s0 s1 : list ascii, s = s0 ++ s1
                            /\ (a :: s0 =~ re1) /\ s1 =~ re2

========================= (1 / 1)

exists s0 s1 : list ascii, s = s0 ++ s1
                        /\ (s0 =~ derive a re1) /\ s1 =~ re2
\end{verbatim}
\caption{Selected output from the interactive proof of Lemma~\ref{Lem:r_derive},
    after opting to prove the left side of the conjunct in one
    subgoal.}\label{F:r_derive2}
\end{figure}

In the second goal, \texttt{H} will be different, as shown in
\figurename~\ref{F:r_derive2}. We can use this version to obtain witnesses for
the existential claim on the left of the goal, and reason with \texttt{IHre1} to
finish the conclusion. We cannot, however, use \texttt{IHre1} directly in the
state shown, even though it would make the claim in \texttt{H} equivalent to the
goal.

This concludes our short tour of Coq via regular expressions. We saw how to
model data and logical propositions inductively, how to build up functional
programs and identify possible proof strategies based on recursion, how to state
correctness in terms of reflection, and how to use and manipulate the proof
context. We also saw the utility of reasoning in traditional logical mechanisms
and converting between the two, as well as the difficulties of reasoning under
existential quantifiers.

By examining these two extended examples, we have seen techniques and challenges
common to program verification. We have also seen some useful features of two
different styles of verifiers; namely, the auto-active Dafny and the interactive
Coq. We continue with a few brief examples of other research that exposes
similar techniques and challenges before providing a variety of other
references.

\subsection{Notable mentions}\label{S:ex_notable}

In this section we will briefly highlight research in verified programs that is
particularly relevant to the insights gained from the previous examples. It will
also introduce some of the open problems to be examined in
Section~\ref{S:discussion}.

\paragraph{RockSalt.} The RockSalt project formally verified a safety-checker
for Google's Native Client in Coq~\cite{Morrisett_2012}. Due to the challenges
in proofs about program translation and specifically proofs about x86 assembly,
the authors decided instead to build and prove correct a software-fault
isolation checker that they claim is smaller and faster than Google's original.
Key components of their development include one of the first formal models of a
large subset of x86, a DSL to specify and automatically analyze architecture
semantics, and a framework for validating models against existing x86
implementations. The DSL is based largely on grammars, regular expressions, and
the derivatives we saw in the extended example. They also model
non-deterministic register-transfer language which they convert to an
interpretable function by means of an oracle---this enables the extraction of
executable code. They consider several model-validation approaches, including
generated programs using \texttt{CSmith} and \texttt{GCC}, which may miss
instructions not used by compilers, and fuzz-testing based on the grammar, which
can capture all instructions included in the grammar. Some unresolved questions
the authors raise include
\begin{itemize}
    \item Formally modeling x86 is difficult: how can we handle concurrency?
    \item Can we embed the DSL in other proof-assistants to arrive at portable
        specifications?
    \item Can we close the gap and verify the C implementation of the checker
        and compile it with CompCert~\cite{Leroy-Compcert-CACM}?
    \item Can we build more advanced checkers?
    \item Reasoning about bit-vectors is more tedious in Coq than in an
        \gls{smt} solver; how can we improve this?
    \item How can we effectively handle case-analysis on 100s of cases? There is
        a need for more automated and robust proof techniques.
\end{itemize}

\paragraph{RustBelt.} The RustBelt project has proven the Rust programming
language's safety guarantees~\cite{Jung_2018a,Jung_2021}. The core of their
arguments rely on inductive judgements like we saw in the extended example,
formalized in Iris~\cite{Jung_2018b} on top of Coq, in order to prove that if a
Rust program that does not use \texttt{unsafe} type-checks, it is indeed safe.
They further demonstrated the conditions necessary for any given \texttt{unsafe}
code to be safe, and proved several facts about the Rust standard library's
\texttt{unsafe} usage, including the discovery of a few bugs. The proof is thus
extendable: the whole program is safe if all the \texttt{unsafe} pieces are
safe. They extended concurrent separation logic to handle Rust's lifetimes,
adapting the spatial reasoning technique to temporal reasoning. There are a few
pieces of the Rust language missing, \eg, traits and \texttt{drop} destructors,
but the work brings new confidence to the safety of Rust.

We cannot mention RustBelt without also mentioning the significant work that has
been put into Iris~\cite{Jung_2015,Jung_2016,Krebbers_2017a,Jung_2018b}. The
team has managed to distill many of the different concurrent separation logics
(recall \figurename~\ref{F:iris_complex}) into a ``raw'' form from which they
may be derived, just like lifetime logic was derived for RustBelt.

\paragraph{Rosette.} Rosette~\cite{Rosette,Torlak_2013} is a language for
building verified languages. That is, in the tradition of Racket, Rosette
enables the creation of new solver-aided languages; like Dafny, Rosette employs
a \gls{smt} solver for automation. Rosette is completely automatic, however, and
enables queries beyond ``is this program correct?'' The solvers automate program
synthesis, verification, bug location, and program repair via a novel technique
called \emph{partial evaluation}. This enables Rosette to be designed around a
small core while programmers and languages use advanced features---the
higher-level code is partially evaluated away into the smaller core. This helps
remove artificial finitization of programs, which is progress over traditional
bounded-reasoning for automatic verifiers. The work on synthesis is also
reminiscent of work on relational interpreters~\cite{Byrd_2012}. Related work
stemming from Rosette has addressed challenges such as symbolic execution with
types~\cite{Chang_2018} and virtual machines~\cite{Torlak_2014}. Most recently
the team has explored the profiling~\cite{Bornholt_2018} and
fixing~\cite{Porncharoenwase_2020} of code that explodes under symbolic
evaluation (recall our trouble with Dafny's timeout demon).

\paragraph{CompCert.} The CompCert
project~\cite{Leroy-Compcert-CACM,Leroy-BKSPF-2016,Kastner-LBSSF-2017} develops
a multi-pass, optimizing, verified C compiler for MISRA-C 2004 (almost all of
ISO C99 is supported). The authors argue that miscompilation is a serious risk,
especially in safety-critical environments---it can invalidate verification
of the program, as the running executable may not be faithful to the verified
program. As of the \citeyear{Kastner-LBSSF-2017} paper, CompCert supports
separate compilation, DWARF debugging information, formal annotations at the C
and assembly level, equivalence checks between the assembly output and the
executable program (part of a translation validation process), and several
processor architectures. CompCert also comes equipped with a reference
interpreter for model-checking, a verified parser (not part of the original
\citeyear{Leroy-Compcert-CACM} development), and is competitive with all but the
highest \texttt{GCC} optimization levels. The CompCert development presents two
useful insights: first, they structure their proof by induction, but the
correctness criteria are similar to the hash table proof above, examining
potential executions for comparison. Second, they mention several ongoing
challenges related to extraction of verified programs like compilers, as well as
challenges specific to compilation and linking.

Recall from the hash table example that the distributed system was correct if
its state machine transitions were comparable to transitions in the single hash
table, with the addition of the stutter step. CompCert, in order to account for
the degrees of freedom given to a C compiler writer (\eg, non-deterministic
order of evaluation, optimizations), similarly weakens the preservation of exact
comparison of observable behaviors and instead considers correctness of safe
programs. The property they are particularly interested in is that behaviors of
compiled safe programs are permitted behaviors of the source
program~\cite[Section~2.1]{Leroy-Compcert-CACM}. They also consider
\emph{traces} of observable behavior in their implementation and
proofs~\cite{Kastner-LBSSF-2017} as well as other possible approaches (\eg,
translation validation and proof-carrying
code)~\cite[Section~2.2]{Leroy-Compcert-CACM}.

CompCert is a program written in Coq; therefore, to execute it, it must be
extracted to a different language. This presents a challenge similar to the one
CompCert is trying to solve---how do you trust the extraction mechanism? It is
desirable to provide and verify an alternative extraction mechanism (\eg, to C)
which can thus be used for bootstrapping the compiler in a completely verified
way. For more on bootstrapping compilers, especially in verified contexts,
see~\cite{Konat_2016,Myreen_2021}. Other unverified components include the
preprocessor, assembler, and linker; the translation-validation approach helps
to restore confidence in those steps~\cite[Section~5]{Kastner-LBSSF-2017}.
Relatedly, cross-language linking has proven a challenge for verification
efforts (see~\cite[Section~4]{Kastner-LBSSF-2017} and~\cite{Wang_2014}).

\paragraph{Jitterbug.} Jitterbug~\cite{258848} was inspired by previous works
(Serval~\cite{Nelson_2019}, Jitk~\cite{186144}, and CompCert's
traces~\cite{Kastner-LBSSF-2017}) to create a tool for building and verifying
single-pass JITs. They were specifically interested in the \gls{bpf} JIT in the
Linux kernel. Jitterbug discharges most proofs via Rosette, and formalizes the
meta-theoretic properties in Lean. Rosette enabled the develoment of a C-like
DSL for building JITs with low-verification overhead. Rosette further allowed
the team to implement synthesized optimizations. There are a number of
unverified components in the implementation, but the development helped find and
fix bugs in the Linux kernel, which is a serious security concern. The proof
also exposed common proof challenges, such as
\begin{itemize}
    \item finding the right inductive invariant,
    \item scaling the proof with existential quantifiers, explosion of symbolic
        execution, and slow arithmetic operations,
    \item cooperation between interactively verified components and automatically
        verified components,
    \item not taking a clean-slate approach to have real-world impact, and
    \item deciding what not to verify, which is often as important as deciding
        what to verify.
\end{itemize}

\paragraph{Serval.} We briefly mentioned Serval above; Serval is a framework for
developing automatic verifiers for systems software~\cite{Nelson_2019}. In the
case-study, the authors retrofit CertikOS~\cite{199344} and
Komodo~\cite{Ferraiuolo_2017} and examined \gls{bpf} compilers in the Linux
kernel. Serval takes advantage of the state machine refinement technique we saw
in the hash table example. Serval notably separates the implementation language
(\eg, C with \texttt{GCC}) from the proof language (a Rosette-built
specification). This naturally begs the question of guaranteeing that the
implementation actually corresponds to the proof; in the case of Serval, the
input for verification is the assembly produced from the implementation. Serval
also exposes challenges related to systems verification, such as memory models,
as well as challenges of scale related to symbolic execution.

\paragraph{Bedrock.} Bedrock is a possibly now-defunct\footnote{The software
appears undeveloped since 2014, though it may just be that the development is
stable.} but still interesting Coq development for low-level verification. The
system enables reasoning about memory management and showcases a method similar
to proof by reflection of verifying programs by comparison with
functional\footnote{In the paradigm sense, rather than in the sense of
``working.''} reference implementations. Bedrock was one of the first systems to
enable reasoning about code pointers as data~\cite{Chlipala_2011} and
cross-language verification~\cite{Wang_2014}. It also provides a case-study in
modular verification via networking and web applications~\cite{Chlipala_2015}.
The development of Coq tactics permits automation even in an interactive
theorem-prover. Bedrock relies on separation logic like we saw in
Section~\ref{S:t_logic}.

\subsection{Further reading}\label{S:ex_reading}

In this section we offer a number of related projects and research for the
interested. The seL4 project has developed a verified
microkernel~\cite{Klein_EHACDEEKNSTW_09,Klein_AEHCDEEKNSTW_10,Klein_AEMSKH_14,Klein_AKMHF_18}.
VeriSafeKV verified a key-value store based on the \(B^\epsilon\)-tree developed
by~\cite{188458}, using techniques gleaned from distributed-systems
verification~\cite{258969}. The IronClad and IronFleet projects built end-to-end
full-stack verification~\cite{hawblitzel2014ironclad,hawblitzel2015ironfleet}.
The Alive project brought verification to high-performance computing and
floating-point computation by verifying peephole
optimizations~\cite{Lopes_2018,Menendez_2016,Lopes_2015}. RedLeaf builds on
SMACK, Boogie, and the Z3 \gls{smt} solver to build a safe and Hoare-logic
verified \gls{os} kernel~\cite{Narayanan_2019,Narayan_2020}. Perennial brought
Iris to a subset of Go to enable reasoning about crash-safe
system~\cite{Chajed_2019}. AtomFS developed the first formally verified
fine-grained concurrent file system and presents a concurrent relational logic
with helpers for reasoning about such systems~\cite{Zou_2019}. Vigor aids the
development of network functions with a push-button, minimal-experience
approach, putting verification in reach for more people and
projects~\cite{Zaostrovnykh_2019}. Hyperkernel brought push-button verification
to a Unix-like kernel~\cite{Nelson_2017}. Komodo illustrates a verified
alternative to Intel's SGX for user-mode enclaves and isolated
execution~\cite{Ferraiuolo_2017}. Pantry extended recent work in proof-based
verifiable computations to handle state, such as computations that interact with
RAM or disks, like MapReduce jobs~\cite{Braun_2013}. Spice extended this result
to formally verified state machines~\cite{222621}. The Ghosts of Departed Proofs
paper introduces proof-carrying code as an API-design technique for
Haskell~\cite{Noonan_2018}. DFSCQ improves on the
Yggdrasil~\cite{Sigurbjarnarson_2016} and FSCQ~\cite{Chen_2015} file-system
performance without sacrificing formal verification of crash-safety and
sophisticated optimizations~\cite{Chen_2017}. SibylFS provides a model of
file-systems that can be used to validate models and test file-systems of
various stripes~\cite{Ridge_2015}. CSPEC is a framework for verifying concurrent
software using mover types to re-order commutative operations~\cite{222565}.
CertiKOS is yet another example of a verified concurrent \gls{os}
kernel~\cite{199344}. For more on translation validation, we
recommend~\cite{Pnueli_1998}, which describes techniques employed in
translation-validation for optimizing compilers~\cite{Necula_2000} and a
verified \gls{os} kernel~\cite{Sewell_2013}. The \gls{vst} provides verifiable
C, a program logic for the C language~\cite{VST,Appel_2011}. Ynot\footnote{which
appears to have stalled since 2010 or 2011} developed a higher order,
dependently typed, monadic approach to verifying effectful programs with
IO~\cite{Nanevski08ynot:reasoning}. Ynot is also a Coq development that encodes
Hoare logic in its effect type, on top of which separation logic is built.
