\section{Learning by example}\label{S:examples}

% TODO I/we and tenses are all over the place

I begin with an extended example comparing two proofs of different systems in
different verification environments (Section~\ref{S:ex_ext}). I then briefly
discuss a few other examples (Section~\ref{S:ex_notable}) and point towards a
plethora of other verified-programs research (Section~\ref{S:ex_reading}).

\subsection{Extended example: distributed hash tables and regular
expressions}\label{S:ex_ext}

I have previously written two proofs of sufficient size and complexity that
their study will demonstrate both common proof techniques and challenges. I will
not provide all the details, in part because both were completed for academic
exercises and I wish to avoid publishing full solutions, and in part because
some details are not relevant for the discussion here (proof scripts and
programs available on request). It is important to note that in one case, there
is no final executable program; rather, the proof is written entirely in a
relational style. This facilitates the proof at the cost of not having a program
to run. A final step would be to implement the full programs and prove its
agreement with the relational definition.

The first proof is that a (somewhat idealized) distributed hash table behaves
like a logically-centralized hash table; this was modeled and proved in
Dafny~\cite{leino2010dafny} for the 2020 Systems Software Verification Summer
School~\cite{Kapritsos_2020}. I defer details on hash tables to classic texts
like~\cite{CLRS}. This proof has no final executable.

The second proof is that the theory of regular expressions and their derivatives
correctly implements regular-expression matching; this was modeled and proved in
Coq~\cite{Coq} for a course using the \emph{Logical Foundations}
text~\cite{Pierce:SF1}. Details on regular expressions may be found
in~\cite{Lewis_1997,Morrisett_2012}; details on the derivatives of regular
expressions, also used in~\cite{Pierce:SF1,Morrisett_2012}, can be found
in~\cite{Might_Yacc,Might_desugar,Might_deriv}. This proof does define a
matching function that can be extracted to OCaml, Haskell, or Scheme;
see~\cite{Coq_Extract} or~\cite[Extraction]{Pierce:SF1} for details.

I present the examples by following the chronology of their development. First,
I develop a model of the theory (Section~\ref{S:ex_theory}). Second, I model the
program to be verified (Section~\ref{S:ex_program}). Third, I write down the
formal specification (Section~\ref{S:ex_spec}). Finally, I prove by induction
that the models implement the specification (Section~\ref{S:ex_ind}).

\subsubsection{Model of the theory}\label{S:ex_theory}

Here I develop the necessary theories of hash tables and regular expressions.
They will be needed especially for the formal specification
(Section~\ref{S:ex_spec}) and proof (Section~\ref{S:ex_ind}).

\paragraph{Hash table.} My theory of hash tables is to use a full Dafny map,
specifically an infinite map from integers to integers. This means every
possible integer key maps to a value; the default is 0. We specify two
relations: the initial state and the possible transitions. This gives us an
inductive state-machine to describe hash tables. The initial state is all keys
map to 0. The possible transitions are the relations \(\func{Get}\) and
\(\func{Put}\), each of which relate a current state to the next state:

\begin{align*}
    \func{Get}(\var{state}, \var{state'}, \var{key}, \var{value}) \definedas\;&
    \var{state}[\var{key}] = \var{value} \\
    & \land \var{state'} = \var{state} \\
    \\
    \func{Put}(\var{state}, \var{state'}, \var{key}, \var{value}) \definedas\;&
    \var{state'} = \var{state}[key \gets value].
\end{align*}

Note that a \(\func{Get}\) leaves the state unchanged; this property will show
up later in other models and is crucial to correctness. Without this statement,
\(\var{state'}\) could be any possible state after a \(\func{Get}\).

In Dafny, I also define
\begin{inlist}
\item a sum-type Step capturing the non-stateful parameters of the transitions
    (here, \(\func{GetStep}\) and \(\func{PutStep}\) capture a key-value pair
    for the \(\func{Get}\) and \(\func{Put}\) relations) and
\item a relation \(\func{Next}\) that asserts the existence of some
    \(\func{Step}\) value such the corresponding transition relation holds.
\end{inlist}

The key takeaway is the modelling of the problem-domain via an inductive
state-machine and relations (or predicates) between possible states. Dafny has
no direct support to indicate that the initial state predicate and the
\(\func{Next}\) predicate form an induction principle; we would need to write a
meta-theoretical proof for that. We can still structure the remaining proofs
inductively and be confident in their correctness.

\paragraph{Regular Expressions.} Coq supports the type of inductive relations
I've used for hash tables; for the theory of regular expressions I will define
what a regular expression is and how a string matches one. I define an inductive
datatype \(\func{regexp}\), parameterized on the type \(T\) of strings, with the
usual alternatives:

\begin{align*}
    \func{regexp}(T) \definedas\;
    & |\; \emptyset \\
    & |\; \epsilon \\
    & |\; \func{Char}(t: T) \\
    & |\; \func{App}(\var{left}: \func{regexp}(T), \var{right}: \func{regexp}(T)) \\
    & |\; \func{Union}(\var{left}: \func{regexp}(T), \var{right}: \func{regexp}(T)) \\
    & |\; \func{Star}(\var{re}: \func{regexp}(T)).
\end{align*}

I also need a theory of ``matching'': what does it mean for a string to match a
regular expression? I write \(s \matches r\) for the assertion that a string
\(s\) is a list of \(T\)s matching a regular-expression \(r\) over the type
\(T\). At this point, there are several options. I could use a reference
implementation and prove that my derivative matcher is equivalent; this requires
that we have a reference implementation, and it still needs to be verified. I could
construct finite automata and write proofs about graphs; according
to~\cite{Morrisett_2012} graphs are unwieldy in Coq. Instead, I'll stick with
induction and define the rules for matching as an inductive proposition:

\begin{mathparpagebreakable}
    \inference[\iname{MEmpty}]{}{[] \matches \epsilon}
    \and
    \inference[\iname{MChar}]{}{[x] \matches \func{Char}(x)}
    \and
    \inference[\iname{MApp}]{s_1 \matches r_1 & s_2 \matches r_2}
    {s_1 \texttt{++} s_2 \matches \func{App}(r_1, r_2)}
    \and
    \inference[\iname{MUnionL}]{s_1 \matches r_1}{s_1 \matches \func{Union}(r_1, r_2)}
    \and
    \inference[\iname{MUnionR}]{s_1 \matches r_2}{s_1 \matches \func{Union}(r_1, r_2)}
    \and
    \inference[\iname{MStar0}]{}{[] \matches \func{Star}(r)}
    \and
    \inference[\iname{MStarApp}]{s_1 \matches r & s_2 \matches \func{Star}(r)}
    {s_1 \texttt{++} s_2 \matches \func{Star}(r)}.
\end{mathparpagebreakable}

Because these are inductive definitions, Coq automatically generates induction
principles for use in proofs. Thus I define the problem-domain inductively,
again.

These definitions can be read analogously to the relational predicates
describing transitions in the hash table state-machine. We can use these rules
to construct proofs that a string matches a regular expression; the only way to
extend these rules is to prove a theorem about the matching relation. Because
Coq is constructive, such a proof will necessarily involve the use of these
rules or another such theorem---unfolded, all proofs about \(\matches\) are built
on these rules and the standard rules of Coq's logic.

The inductive construction turns out to be a good pattern for verified programs;
only the simplest programs make use of purely finite types (\eg, booleans) and
can be verified with a finite case analysis. Most interesting programs require
reasoning by induction to handle the infinite.

\subsubsection{Model of the program}\label{S:ex_program}

Here I develop programs for distributed hash table communication and
regular-expression matching. It is these programs that we wish to prove
implement specifications of the above theories.

\paragraph{Distributed Hash table.} I need a number of definitions to represent
the network and hosts that will communicate. I begin by axiomatizing the number
of hosts to be some fixed but unknown \(n\) and gathering the set of ids where
\(0 \le id < n\). Next, I model the network: in its idealized representation, it
sends messages only once. The network is \emph{also} an inductive state machine;
each step consists of an \(\func{Action}\) representing an optional message for
a host to receive which must have been sent and a set of messages to be
delivered in the future. I then abstractly model a distributed system in this
network: the system requires definitions for the message and host types, as well
as inductive state-machine predicates for the host (\(\func{HostInit}\) and
\(\func{HostNext}\)). Each host is told its id by the distributed system. It
then collects a map of all ids to hosts and generalizes the host state-machine
as follows: the initial state of the system is that each host and the network is
initialized. The transition is taken by only a single host at a time, in
lock-step with the network; that is, the abstract system's \(\func{Next}\)
predicate keeps all hosts but one the same---that host is given to
\(\func{HostNext}\), and the network to the corresponding \(\func{NetNext}\).
Finally, to conclude the program, I define a host for use in the distributed
hash table and instantiate the abstract distributed system accordingly. Host 0
starts with the entire hash table (all keys mapped to 0). The other hosts are
empty. The predicates and types for \(\func{HostNext}\) incorporate a network
\(\func{Action}\); the possibilities include updated versions of \(\func{Get}\)
and \(\func{Put}\):

\begin{align*}
    & \func{Get}(\var{state}, \var{state'}, \var{action}, \var{key}, \var{value}) \definedas\; \\
    & \quad \var{key} \in \var{state} & \text{A host can only get keys in its table} \\
    & \quad \land \var{state}[\var{key}] = \var{value} \\
    & \quad \land \var{state'} = \var{state} \\
    & \quad \land \var{action.receive} = \func{None} & \text{No messages received} \\
    & \quad \land \var{action.send} = \emptyset & \text{No messages sent} \\
    \\
    & \func{Put}(\var{state}, \var{state'}, \var{key}, \var{value}) \definedas\; \\
    & \quad \var{key} \in \var{state} & \text{A host can only update keys in its table} \\
    & \quad \land \var{state'} = \var{state}[\var{key} \gets \var{value}] \\
    & \quad \land \var{action.receive} = \func{None} & \text{No messages received} \\
    & \quad \land \var{action.send} = \emptyset & \text{No messages sent.}
\end{align*}

In order for the distributed system to do anything interesting, I also include
the ability to send and receive hash tables. Note that in \(\func{Receive}\) the
receiving host will prefer its own key-value pair to one in the message when the
keys are the same (\ie, in case of conflict, the recipient takes precedence).

\begin{align*}
    & \func{Send}(\var{state}, \var{state'}, \var{action}, \var{message}) \definedas\; \\
    & \quad \var{action.send} = \set{\var{message}}  & \text{The host sends a message} \\
    & \quad \land \var{action.receive} = \func{None} & \text{No messages received} \\
    & \quad \land \var{message} \subseteq \var{state} & \text{The message is a subset of the host's table} \\
    & \quad \land \forall \var{key} \in \var{message} : \var{message}[\var{key}] = \var{state}[\var{key}]
        & \text{The message agrees with the host on the values} \\
    & \quad \land \var{state'} = \var{state} \setminus \var{message}
        & \text{The host removes sent key-value pairs}\\
    \\
    & \func{Receive}(\var{state}, \var{state'}, \var{action}) \definedas\; \\
    & \quad \var{action.send} = \emptyset & \text{No messages sent} \\
    & \quad \land \var{action.receive} = \func{Some}(\var{table})
        & \text{The host receives a message with a table} \\
    & \quad \land \var{state'} = \var{state} \uplus \var{table}
        & \text{The host updates its key-value pairs.}
\end{align*}

The key take-away is that this model of the program follows a suitably similar
inductive state-machine relation as that of the original hash table. The key
differences are network and distributed system abstractions and their
incorporation into the host state-machine. The use of abstract models makes the
model more re-usable and enables layering---proofs about low=level systems can be
nicely composed with proofs about the high-level via refinement, which I will
discuss in Section~\ref{S:ex_spec}. We say that the distributed hash table
model \emph{refines} the distributed system model.

\paragraph{Regular Expressions.} Following the theory of derivatives of regular
expressions, we are interested in a regular-expression matching function that
correctly tests whether or not a string matches a regular expression.

The result of the derivative \(D_a(r)\) is a regular expression that matches all
words that \(r\) matched without the leading \(a\). In the language of formal
languages:

\begin{equation*}
    \mc{L}(D_a(r)) = \setbuild{w}{a + w \in \mc{L}(r)}.
\end{equation*}

To write a matching function with derivatives is to continuously take the
regular expression's derivative with respect to the characters in the string;
only if the final expression matches the empty string is the result considered a
match. More details on the algorithm and definitions are
in~\cite{Might_Yacc,Might_desugar,Might_deriv}. To formalize these definitions
in Coq, I write three recursive functions (``Fix point''s in Cog's lingo). The
first tests whether or not a regular-expression matches the empty string in the
obvious way:

\begin{align*}
    \func{Empty}(\emptyset) &= \false \\
    \func{Empty}(\epsilon) &= \true \\
    \func{Empty}(\func{Char}(\_)) &= \false \\
    \func{Empty}(\func{App}(\var{left}, \var{right})) &=
        \func{Empty}(\var{left}) \text{ and } \func{Empty}(\var{right}) \\
    \func{Empty}(\func{Union}(\var{left}, \var{right})) &=
        \func{Empty}(\var{left}) \text{ or } \func{Empty}(\var{right}) \\
    \func{Empty}(\func{Star}(\_)) &= \true.
\end{align*}

The second computes the derivative of a regular expression with respect to a
particular character; the only non-obvious rule is for \(\func{App}\), where we
must carefully consider whether or not \(\var{left}\) can match an empty string:

\begin{align*}
    \func{D}_a(\emptyset) &= \emptyset \\
    \func{D}_a(\epsilon) &= \emptyset \\
    \func{D}_a(\func{Char}(c)) &= \begin{cases}
        \epsilon & a = c \\
        \emptyset & a \neq c
    \end{cases} \\
    \func{D}_a(\func{App}(\var{left}, \var{right})) &= \begin{cases}
        \func{Union}(\func{App}(\func{D}_a(\var{left}), \var{right}),
                     \func{D}_a(\var{right})) & \func{Empty}(\var{left}) \\
        \func{Union}(\func{App}(\func{D}_a(\var{left}), \var{right}),
                     \emptyset) & \text{otherwise}
    \end{cases} \\
    \func{D}_a(\func{Union}(\var{left}, \var{right})) &=
        \func{Union}(\func{D}_a(\var{left}), \func{D}_a(\var{right})) \\
    \func{D}_a(\func{Star}(r)) &= \func{App}(\func{D}_a(r), \func{Star}(r)).
\end{align*}

The third implements our matching algorithm:

\begin{align*}
    \func{Match}([], r) &= \func{Empty}(r) \\
    \func{Match}(a+w, r) &= \func{Match}(w, \func{D}_a(r))
\end{align*}

It may not appear that I used inductive definitions to model our
regular-expression matching program, but the close relationship between
recursive functions and induction hints at the nature of our program. Indeed, as
I have already stated, the equivalence proofs will all be by induction. Pay
attention to the inductive structure of the functions: \(\func{Empty}\) and
\(\func{D}\) are recursive on the regular expression, while \(\func{Match}\) is
recursive on the string. This is a strong clue for the proof-writer about the
direction to take in the actual proof.

The two programs are noticeably different: in one, I define another
state-machine in terms of relations between states. In the other, I provide
computable functions over data. Yet the proofs will have striking similarities.
Besides the key difference of executability, there is also a difference in
abstraction level. The hash table example models an idealized network and an
abstract distributed system instantiated with a particular protocol for host
communication. The regular expression example is abstract only in the type of
characters in the string with the restriction that equality of two characters
must be decidable. In addition, the hash table example lacks any formalizations
relating the initial and next predicates; they are designed to form an induction
principle\footnote{For a introductory treatment of induction principles in Coq,
see~\cite[Induction Principles]{Pierce:SF1}}, but a meta-theoretic proof is
needed to show that they are. The regular expression program needs no induction
principles; they are already provided by the regular expression type and the
definition of the matches relation.

\subsubsection{Formal specification}\label{S:ex_spec}

In this section I discuss the specification the two programs must meet, first
informally and then formally.

\paragraph{Hash table.} Informally, we would like the distributed hash table
state machines to behave collectively like the state machine for a single hash
table. As a first try, we might want the states to be equivalent step for step.
That is, each step in the single hash table should correspond to a step in the
distributed system. For this, we need a function that maps the distributed
system state into the state of a single hash-table; the simplest version is to
collect all the maps in the system, union them together, and then guarantee the
resulting map is full by returning the all-zero map in the case that it is not
full. A correct implementation will need to avoid falling in to the all-zero map
case by maintaining a full map across all the hosts---this is so that a
\(\func{Put}\) step in the single hash table is accurately reflected in the
distributed system and \emph{vice-versa}.

There is a subtle problem with the strict equivalence above: notice that, if the
program is correct, \(\func{Send}\) and \(\func{Receive}\) in the distributed
system should not change the overall state of the collective key-value pairs.
There is no corresponding state-change in the single hash table! To overcome
this challenge, I introduce the notion of a \emph{stutter step}. This is a faux
state-change wherein the state is actually unchanged. That is, the actual
correctness criterion is that, whenever the distributed system takes a step via
its \(\func{Next}\) predicate, the single hash table either also takes a step or
remains the same (a stutter step).

I formalize this in two proof obligations, or theorems, about the program. Let
the function \(I\) be an interpretation function mapping distributed system
state into single hash-table state. The theorems resemble the two stages of
induction: a base case (Theorem~\ref{Th:h_init}) and an inductive case
(Theorem~\ref{Th:h_ind}). In inductive proofs, we wish to prove some proposition
\(P\) for all possible elements. Thus the programmer supplies \(P\) as a
predicate \(\func{Inv}\) that is maintained by their program. The goal is for
\(\func{Inv}\) to imply the desired safety or correctness properties; it is also
allowed to contain other additional invariants. In many cases these additional
invariants is necessary to correctness.

Below, I will use the subscript \(D\) to represent functions and propositions
about the distributed system, and \(S\) for the same about the single hash
table.

\begin{thm}[Initial state correctness]\label{Th:h_init}
    For all distributed system states \(s\), we have
    \begin{align*}
        \func{Init}_{D}(s) \implies \\
        \func{Inv}(s) \land \func{Init}_{S}(I(s)).
    \end{align*}
\end{thm}

\begin{thm}[Inductive state correctness]\label{Th:h_ind}
    For all distributed system states \(s, s'\), we have
    \begin{align*}
        \func{Inv}(s) \land \func{Next}_{D}(s, s') \implies \\
        \func{Inv}(s') \land (\func{Next}_{S}(I(s), I(s')) \lor I(s) = I(s')).
    \end{align*}
\end{thm}

Notice that we still need a meta-theoretic proof that for all propositions \(P\)
about the distributed system state, Theorems~\ref{Th:h_init} and~\ref{Th:h_ind}
imply that \(P\) holds for all state.

\begin{rem}
    Hiding behind the \(D\) subscript is the network: the collection of tables
    in the distributed system is not limited to all the tables currently on the
    hosts. It must also include any tables that ``in transit'' on the network!
    Otherwise keys might temporarily ``disappear,'' causing them to be lost. We
    would not be able to finish the proof if we ignored the network in our
    interpretation function \(I\).
\end{rem}

Specifying the invariant correctly for Dafny often involves an educated guess:
start with the direct correctness or safety conditions, and then add needed
information as you discover that you need it during the inductive process. Here,
the critical properties are that all the tables at each host are disjoint (so
that each key is owned by exactly one node) and that the overall collection of
host state is a full table (so that no keys have disappeared).

One challenge in a system like Dafny is that we must make the structure of our
proof explicit in the specification: we are clearly proceeding with a proof that
resembles induction. A unique takeaway from this particular problem is the
pairing of state-machine transitions to prove that the observable behavior is
the same. This style of proof is especially relevant for proofs about large
classes of programs, like for verified compilers. We'll see an example in
Section~\ref{S:ex_notable}.

\paragraph{Regular Expressions.} Informally, we need \(\func{Match}\) to
correctly implement matching; that is, \(\func{Match}(s, r)\) should be
\(\true\) whenever \(s \matches r\). But \(\func{Match}\) is a (decidable)
boolean and the matches relation is a proposition, which is in general
undecidable. The two are not directly compatible with connectives like \(\iff\);
that is, we cannot right \(\forall s, r: \func{Match}(s, r) \iff s \matches r\)
as our specification. I could instead use the proposition \(\func{Match}(s,
r) = \true\), but I choose to use a technique called ``proof by
reflection.'' The idea is that some propositions are in fact decidable; as a
witness, we provide a predicate that computes the truth-value. The predicate is
said to \emph{reflect} the proposition. I will write \(b \reflects P\) in these
cases; note that implicitly \(\neg b \reflects \neg P\). To prove such a claim,
we must show that in each possible case of the computation of \(b\), the
proposition \(P\) is provable or derives a contradiction. We are able to make
use of the (proved) fact that \(b \reflects P \equiv b = true \iff P\).

Thus we state our proof obligation:
\begin{thm}[Match correctness]\label{Th:r_match}
    For all strings \(s\) and regular expressions \(r\), we have
    \(\func{Match}(s, r) \reflects s \matches r\).
\end{thm}

As we will see, we will also need correctness for the other two functions. The
correctness theorem for \(\func{Empty}\) is simple:
\begin{lem}[Empty correctness]\label{Lem:r_empty}
    For all regular expressions \(r\), we have \\
    \(\func{Empty}(r) \reflects [] \matches r\).
\end{lem}

For the derivative, we need to formalize what it means to be a derivative. I
define the relation \(\Delta\) between two regular expressions \(r\) and \(r'\)
with respect to character \(a\) as for all strings \(s\), \(\forall s: a+s
\matches r \iff s \matches r'\). That is, \(\Delta(r, a, r')\) is provable
exactly when \(r'\) is the derivative of \(r\) with respect to \(a\). Then the
correctness theorem for \(\func{D}\) is stated as:
\begin{lem}[Derivative correctness]\label{Lem:r_derive}
    For all characters \(a\) and regular expressions \(r\), we have
    \(\Delta(r, a, \func{D}_a(r))\).
\end{lem}

Proof by reflection is a common and powerful technique for relating predicates
to propositions and for doing case-analysis over propositions in logics without
the law of excluded middle\footnote{The LEM states \(\forall P, P \lor \neg P\).
This is not assumed by Coq as Coq uses a constructive logic. It is possible to
add the axiom; however, this has the effect of changing the logic in a subtle
way.}. The rules of reflection are succinctly stated:

\begin{mathpar}
    \inference[\iname{Reflect-T}]{P}{\true \reflects P} \and
    \inference[\iname{Reflect-F}]{\neg P}{\false \reflects P}
\end{mathpar}

In this example we also need auxiliary correctness statements; we will see
analogues in the hash-table proof. The difference is that, from our development
of the \(\func{Match}\) function, we know we need \(\func{Empty}\) and
\(\func{D}\) to be correct. In the hash table case, I've hidden some of the
analogous functions in notation---I end up needing information about table union
and removal, fullness, disjointness, and the location of tables in order to
complete the proof.

\subsubsection{Proof by induction}\label{S:ex_ind}

Finally we come to the proofs. I will omit the details and focus on a few key
ideas.

In the case of the hash table proof, we are interested in the following: first,
Dafny can automatically prove some lemmas and fill in some details in theorems.
This avoids some tedium, at the cost of hiding the exact proof state. Second,
proof development in Dafny follows a sort of 20-questions style. Lastly, Dafny
suffers from a ``timeout demon'' due to the use of an \gls{smt} solver. This
leads to some challenges in large proof developments.

In the case of regular expressions, we are interested in the following: first,
there is a clever technique of relating relating our inductive judgements to
meaningful propositions that simplifies the reflection proof. As a challenge,
however, Coq struggles to apply theorems under existential quantifiers. Second,
while not used to its full extent in my proof script, Coq allows expressive
proof-automation, albeit not as automatically as Dafny. Third, the Cog proof is
entirely interactive, so that I know exactly what context I am in and what the
goals are at any time. This can make it easier to reason about complex state, as
I am not guessing what the system looks like.

\paragraph{Hash table.} Looking at our two proof obligations,
Theorem~\ref{Th:h_init} seems the easier of the two: we need to prove that
\(\func{Init}_{D}\) is correct with respect to \(\func{Init}_{S}\) and that it
establishes the invariants (disjointness and fullness). After I write the
statement of the theorem, Dafny asks for a proof. I first let it attempt to fill
in the details, leaving the body blank; Dafny complains that the two
post-conditions (correctness and the invariants) may not hold. This is Dafny's
way of telling me that it can't work out all the details. By examining the
definition of \(\func{Init}_{S}\), I know I need to first show that \(I\) maps
the initial distributed state to the initial single state. Logically, I know
that one host contains the full 0-table, and the other hosts' tables are empty,
so they shouldn't contribute to the result. I also know there is nothing on the
network. I ask Dafny: if I can prove these few facts, will you believe
correctness of \(\func{Init}\)? To do so, I \texttt{assert} the following facts
without proof:
\begin{itemize}
    \item the host with id 0 contains a table mapping all keys to 0;
    \item any host with id not 0 contains an empty table;
    \item the table-union of a non-empty table and any number of other empty
        tables is the non-empty table;
    \item there are no messages on the network; and therefore
    \item \(I\) maps the initial distributed state to the initial single state
        by considering a table-union of a single full 0-table with empty-tables.
\end{itemize}
Indeed, at this point, Dafny no longer complains that the \(\func{Init}_{S}\)
post-condition cannot be established. However, it does flag some (not all!) of
the assertions as not established. In other words, if I can prove the remaining
assertions, I will have successfully given Dafny enough to finish part of the
proof. Dafny observes on its own all of the facts except that empty tables do
not contribute to a table-union. I state this as a separate lemma and play
another round of 20-questions with Dafny: what will it take to convince you?
Briefly, I am able to complete the proof via an inductive structure that mimics
the recursive nature of the table-union function---I am able to invoke the lemma
I am proving in the recursive case, much like a recursive function call. An
important auxiliary lemma in the proof is that the table-union of empty tables
is also empty: this has no proof body, for Dafny can observe its truth entirely
automatically. I still need to show the invariants, but fullness follows from
the establishment of \(\func{Init}_{S}\), and the tables are also clearly
disjoint by similar reasoning; Dafny fills in most of these details for me.

The proof of Theorem~\ref{Th:h_ind} is similar in many respects: I ask Dafny if
it can prove the required definitions automatically; where it cannot, I start
unfolding definitions and \texttt{assert}ing facts until Dafny has enough
information. Then, I supply proofs for the assertions. I also have to reason by
case-analysis on the possible steps for the distributed system (recall from
Section~\ref{S:ex_program} the steps \(\func{Get}\), \(\func{Put}\),
\(\func{Send}\), and \(\func{Receive}\)). Some cases require more details then
others; I wind up needing auxiliary statements like ``if all the tables are
disjoint, then the table that owns the key controls the value that the key maps
to in the table-union'' and ``the invariants disjointness and fullness imply
that the union is also full'' (both of which Dafny fills in almost
automatically). Similarly, with little assistance Dafny can see that a
\(\func{Put}\) step keeps full maps full. However, as the proof starts to get
larger, and the more complicated details are filled in, Dafny's checker gets
slower and slower. It eventually grinds to a halt---I, the programmer,
am left with a tool that should be mostly automatic but has effectively stopped
its dialogue with me. What went wrong?

By limiting the time spent per proof, I identify that I am stuck in Dafny's
``timeout demon.'' A full tutorial on profiling Dafny execution to identify the
source of the timeout is out of scope; see~\cite{Kapritsos_2020} for details.
The source of the demon is related to the way Dafny and its underlying engine
and solver unfold definitions and attempt to use them. In this case, two
different definitions make trouble: disjointness and fullness. Let's examine
their definitions:
\begin{align*}
    \func{Disjoint}(\var{tables}) &\definedas \forall t_1, t_2 \in \var{tables}:
    t_1 \neq t_2 \implies \func{Keys}(t_1) \intersect \func{Keys}(t_2) = \emptyset
    \\ \text{and} \\
    \func{Full}(\var{tables}) &\definedas \forall \var{key} : \exists t \in
    \var{tables} : \var{key} \in t.
\end{align*}
In the case of disjointness, Dafny might try to apply the definition anywhere
there are tables to make progress; unfortunately, there are lots of tables in
the proofs, so this leads to an explosion of applications that make little
progress. In the case of fullness, Dafny struggles to resolve the
universal-existential pair, leading to similar explosions or slowdowns. The
resolution in both cases is to mark the definitions \texttt{\{:opaque\}}, an
annotation that prevents Dafny from unfolding the definitions except when
explicitly \texttt{reveal}ed---this gives the programmer more control over the
scope of the definitions, but closes off an avenue of automation. Now, I have to
rework previously acceptable proofs to reveal definitions at the key steps so
that Dafny can see I have satisfied them. When filling in these details, as
before, I am not shown the exact proof state, and have to continue parts of the
20-questions game.

This concludes our short tour of Dafny via distributed hash tables. We saw how
to model inductive state machines for both theoretical and practical models, how
to state correctness criteria for an inductive proposition, and how to use
Dafny's auto-active features to assist proof-development. We also saw the cost
of that auto-activity in the ``timeout demon'' and the lack of visible context.

\paragraph{Regular Expressions.} Let's first examine the proof of
\(\func{Match}\) correctness. Lemmas~\ref{Lem:r_empty} and~\ref{Lem:r_derive}
make the proof of Theorem~\ref{Th:r_match} straightforward; we proceed by
induction on the string \(s\), since \(\func{Match}\) recurs on it. The
correctness of \(\func{Empty}\) demonstrates the base case (\(s = []\)). In the
inductive case (\(s = x + w\)), we can use the induction hypothesis on the
derivative of the regular expression with respect to \(x\). This, combined with
\(\func{D}\) correctness, is enough to finish the proof.

The proofs of our two lemmas actually hide much of the detail of the final
proof. They also proceed by induction, but on a regular expression. In order to
make use of the statements about \(\matches\) that the induction hypothesis
gives us, we would like to reason with more traditional logical connectives.
Thus we first prove a series of lemmas connecting the inference rules (\eg,
\iname{MUnionL}, \iname{MStar0}) and regular expression constructors (\eg,
\(\func{Union}\), \(\func{Star}\)) to more natural propositions. As an example,
it is straightforward to show that
\begin{equation*}
    \forall s, \var{left}, \var{right}:
    s \matches \func{Union}(\var{left}, \var{right})
    \iff
    s \matches \var{left} \lor s \matches \var{right}.
\end{equation*}
We often need to show these statements by induction, but the only interesting
cases are when the overall regular expression is of the type we care about. With
Coq's automation\footnote{A full overview is out of scope. The Coq manual,
accessible from the Coq homepage~\cite{Coq}, explains how to use the automation
language Ltac as well as automation tacticals.}, we can automatically discard
all the other cases and focus on just the details of the particular case (this
is particular useful in the cases for \(\func{Star}\)).

These propositions end up being more amenable to use with the induction
hypotheses. However, we run into trouble with \(\func{App}\) and
\(\func{Star}\). Their logical equivalents involve the use of the existential
quantifier; Coq's constructive logic requires us to give a witness to complete
the proof.
\begin{lem}
    For all strings \(s\) and regular expressions \(\var{left}, \var{right}\),
    we have
    \begin{mathpar}
        s \matches \func{App}(\var{left}, \var{right}) \\
        \iff \\
        \exists s_0, s_1: s = s_0 \texttt{++} s_1 \land s_0 \matches \var{left} \land s_1 \matches \var{right}
    \end{mathpar}
\end{lem}
\begin{lem}
    For all strings \(a + s\) and regular expressions \(\var{left}, \var{right}\),
    we have
    \begin{mathpar}
        a + s \matches \func{App}(\var{left}, \var{right}) \\
        \iff \\
        [] \matches \var{left} \land a + s \matches \var{right} \\
        \lor \\
        \exists s_0, s_1: s = s_0 \texttt{++} s_1 \land a + s_0 \matches \var{left} \land s_1 \matches \var{right}
    \end{mathpar}
\end{lem}
\begin{lem}
    For all strings \(a + s\) and regular expressions \(r\), we have
    \begin{mathpar}
        a + s \matches \func{Star}(r) \\
        \iff \\
        \exists s_0, s_1: s = s_0 \texttt{++} s_1 \land s_0 \matches r \land s_1 \matches \func{Star}(r)
    \end{mathpar}
\end{lem}
This prevents us from performing certain obvious rewrites that in
other situations would make the proof simpler. The issue is further demonstrated
in the excerpts below.

One useful feature of Coq, particularly in the proof of correctness of
\(\func{D}\), is the interactive state. As a rather verbose example that also
demonstrates the rewrite-under-existential issue above, I show a sample from the
correctness proof of \(\func{D}\) in the \(\func{App}\) case. Note how Coq shows
the goals to prove and the hypotheses and variables in the current context. (One
might wish to use \texttt{IHre1} in a few goals below, but the relevant terms
are stuck under \texttt{exists}.) In this state, I can focus on a particular
subgoal and its associated context and see explicitly all of the proof state.

\begin{verbatim}
4 subgoals
(2 unfocused at this level)

re1, re2 : reg_exp ascii
IHre1 : forall (s : list ascii) (a : ascii), a :: s =~ re1 <-> s =~ derive a re1
IHre2 : forall (s : list ascii) (a : ascii), a :: s =~ re2 <-> s =~ derive a re2
s : list ascii
a : ascii
H : ([ ] =~ re1) /\ s =~ derive a re2

========================= (1 / 4)

(exists s0 s1 : list ascii, s = s0 ++ s1 /\ (s0 =~ derive a re1) /\ s1 =~ re2)
\/ s =~ (if match_eps re1 then derive a re2 else EmptySet)

========================= (2 / 4)

(exists s0 s1 : list ascii, s = s0 ++ s1 /\ (s0 =~ derive a re1) /\ s1 =~ re2)
\/ s =~ (if match_eps re1 then derive a re2 else EmptySet)

========================= (3 / 4)

([ ] =~ re1) /\ s =~ derive a re2
\/ (exists s0 s1 : list ascii, s = s0 ++ s1 /\ (a :: s0 =~ re1) /\ s1 =~ re2)

========================= (4 / 4)

([ ] =~ re1) /\ s =~ derive a re2
\/ (exists s0 s1 : list ascii, s = s0 ++ s1 /\ (a :: s0 =~ re1) /\ s1 =~ re2)
\end{verbatim}

In the first goal, for example, I can proceed on the cases of our
\(\func{Empty}\) reflection lemma: either \(\func{Empty}(\var{re_1})\) is true
and the conditional collapses to \(s \matches \func{D}_a(\var{re_2})\), in which
case the right side of the disjunct follows by the right side of the conjunct
\texttt{H}; or, we have a contradiction, since by the left side of \texttt{H} we have \([]
\matches \var{re_1}\) but case analysis said \([] \not\matches \var{re_1}\)
since \(\func{Empty}(\var{re_1})\) is false.

In the second goal, \texttt{H} will be different, as shown (after opting to
prove the left side of the conjunct):
\begin{verbatim}
1 subgoal
(2 unfocused at this level)

re1, re2 : reg_exp ascii
IHre1 : forall (s : list ascii) (a : ascii), a :: s =~ re1 <-> s =~ derive a re1
IHre2 : forall (s : list ascii) (a : ascii), a :: s =~ re2 <-> s =~ derive a re2
s : list ascii
a : ascii
H : exists s0 s1 : list ascii, s = s0 ++ s1 /\ (a :: s0 =~ re1) /\ s1 =~ re2

========================= (1 / 1)

exists s0 s1 : list ascii, s = s0 ++ s1 /\ (s0 =~ derive a re1) /\ s1 =~ re2
\end{verbatim}
I can use this version to obtain witness for the existential claim on the left
of the goal, and reason with \texttt{IHre1} to finish the conclusion. I cannot,
however, use \texttt{IHre1} directly in the state shown, even though it would
make the claim in \texttt{H} equivalent to the goal.

This concludes our short tour of Coq via regular expressions. We saw how to
model data and logical propositions inductively, how to build up functional
programs and identify possible proof strategies based on recursion, how to state
correctness in terms of reflection, and how to use and manipulate the proof
context. We also saw the utility of reasoning in traditional logical mechanisms
and converting between the two, as well as the difficulties of reasoning under
existential quantifiers.

By examining these two extended examples, we have seen techniques and challenges
common to program verification. We have also seen some useful features of two
different styles of verifiers; namely, the auto-active Dafny and the interactive
Coq. We continue with a few brief examples of other research that exposes
similar techniques and challenges before leaving a variety of other references.

\subsection{Notable mentions}\label{S:ex_notable}

\subsection{Further reading}\label{S:ex_reading}
