\section{Introduction}

First, we introduce the ideas of formal methods and formal verification, in
particular their connection to programming. Next, we briefly dissect the various
layers of abstraction that programmers operate in and the corresponding
layers of verification. Finally, we outline the direction of the rest of this
report.

\subsection{Background}\label{S:background}

Formal methods are mathematical techniques for describing and verifying system
properties~\cite{Wing_90}. They have been successfully applied to the practice
of programming and computation since the birth of computing:
\citeauthor{Turing_1937}'s famous 1937 discussion of the {\haltprob} is an
application of mathematical reasoning to a generalized system of
computation~\cite{Turing_1937}. The use of formal methods continued throughout
the modern computing era, with \citeauthor{McCarthy_67} formalizing the first
proof of a verified compiler in 1967~\cite{McCarthy_67}. The proof was later
mechanically verified to be correct in 1972~\cite{Milner_72}. The computing
giant and prolific writer \citeauthor{EWD:EWD1036} argued in 1988 that the very
nature of programming depended on notions of symbolic manipulation, formal
semantics, and the task of giving a ``formal proof'' that the proposed program
``meets the equally formal functional specification''---and that Computer
Science education at the time generally omitted much of the relevant background
and material necessary for accomplishing this task~\cite{EWD:EWD1036}.

Formal verification, \citeauthor{EWD:EWD1036}'s act of proving that the program
implements its specification, has not died as he predicted through a ``foggy
crystal ball.'' Instead, formal methods have become increasingly powerful,
accessible, and vital, as we aim to elucidate here. Some computer scientists
hesitate to make claims about the termination of a particular
program~\cite{Cook_2011}, perhaps intimidated by \citeauthor{Turing_1937}'s
Halting Problem arguments; yet, proofs of termination, correctness,
non-interference, and more are increasingly necessary and useful to reason about
programs. For example, such proofs are now used to reason about \gls{os}
kernels~\cite{Klein_EHACDEEKNSTW_09,Klein_AEHCDEEKNSTW_10,Klein_AEMSKH_14,Sewell_KH_16,Narayanan_2019,Narayan_2020,Nelson_2017},
safety-critical systems such as avionics~\cite[\S 1]{Leroy-Compcert-CACM},
in-kernel compilers~\cite{186144,258848}, file-systems~\cite{Zou_2019}, and
concurrent systems~\cite{222565,222621}. These are just a few modern systems
examples; verification has made its way into everyday programming, with
applications to, \eg, web-scraping, spatial programming, and superoptimization
for bitvector programs~\cite[\S 4]{Torlak_2013}.

In parallel to the growing formal verification efforts, rising development
complexity presents ongoing challenges to the development and correctness of
software. This is unfortunately coupled with the increasing power of
verification tools---the latter is necessary to make verification amenable.
Consequently, the verification tools also exhibit increasing complexity, with
some being essentially expert systems\footnote{For a glance at the complexity of
some systems, see~\cite{Jung_2015,Jung_2016,Krebbers_2017a,Jung_2018b} and
\figurename~\ref{F:iris_complex}.}. Other systems combine automation with domain
knowledge to create a narrower, more accessible tool. We will see some examples
of this complexity and automation in Section~\ref{S:examples}.

\subsection{The Verified Programming Stack}\label{S:stack}

To examine the technology behind verified programs, it will be helpful to
understand the layers of abstraction in today's programming environments and the
corresponding verification layers. We present a brief overview of these layers,
with notes on what we will cover in the remainder of this report and what is out
of scope; where possible, references are provided for further reading.

The general idea is that, in order to fully trust a program implements its
specification, we need two things. First, we need a proof at the source layer.
The source-layer proof verifies that the program correctly implements its
specification. Second, we need a proof that each intermediate layer preserves
the validity of the previous layer's proof. The composition of these
intermediate-layer proofs guarantees that execution preserves the properties of
the specification without repeating the work of the source-layer proof at each
layer.

\begin{figure}[ht]
    \centering
    \begin{tikzpicture}[stack/.style={rectangle split, rectangle split parts=5, draw, anchor=center}]
        \node[stack](prog){%
            \nodepart{one}Program source
            \nodepart{two}Compiler or Interpreter
            \nodepart{three}Executable Machine Code
            \nodepart{four}\gls{os} and Kernel
            \nodepart{five}Hardware
        };
        \node[stack,right=of prog](verification){%
            \nodepart{one}Program verification
            \nodepart{two}Verified compilers or interpreters
            \nodepart{three}Translation Validation
            \nodepart{four}Verified \gls{os} and Kernel
            \nodepart{five}Verified Hardware
        };
        \draw[<->] (prog.one east) -- (verification.one west);
        \draw[<->] (prog.two east) -- (verification.two west);
        \draw[<->] (prog.three east) -- (verification.three west);
        \draw[<->] (prog.four east) -- (verification.four west);
        \draw[<->] (prog.five east) -- (verification.five west);
    \end{tikzpicture}
    \caption{A simplified programming environment and execution stack, with corresponding verification technology}\label{F:abstraction}
\end{figure}

The model presented in \figurename~\ref{F:abstraction} generally ignores
distributed systems and newer environments like the cloud; here we are primarily
concerned with a program running on a single machine, though it is possible to
generalize the model. We also ignore containerization, orchestration, and build
and deployment pipelines insofar as they are represented as user-space programs
or compositions thereof. Build pipelines naturally include compilers, which are
shown in the model despite being user-space programs.

Also out of scope is full-stack verification in the vein of
IronClad~\cite{hawblitzel2014ironclad} and
IronFleet~\cite{hawblitzel2015ironfleet}. Here we are considering the individual
components, especially the top layers.

At the very top of the stack, we have the program source. Whether high-level or
low-level, this is the definition of what we want the computer to do.
Verification requires a formal specification of that behavior and a proof that
the source-as-written, coupled with the language's formal semantics, implement
that behavior. This report focuses on tools and techniques for accomplishing
this task. Some key components include
\begin{inlist}
\item the kind of verifier (\eg, push-button or interactive);
\item the logic of the verifier (\eg, \gls{smt} or higher-order constructive
    propositional logic via \gls{coc}); and
\item the logical system of the proof (\eg, separation logic).
\end{inlist}

In order to execute the program, we have the remaining layers. In order:
\begin{enumerate}
    \item\label{i:stack_translator} A program translator (compiler or
        interpreter)\footnote{These are almost eschewed in the case of the
        assembly programmer; yet, there is still the assembler or linker to
        contend with.}
    \item\label{i:stack_asm} The produced executable machine code (\eg, ELF
        binaries)
    \item\label{i:stack_OS} The \gls{os} and kernel responsible for managing execution
        of the machine code
    \item\label{i:stack_hardware} The underlying hardware that carries out the
        instructions
\end{enumerate}

Item~\ref{i:stack_translator} produces executable machine code, possibly through
several stages of translation. In safety-critical systems, it is vital that
there be no mis-translation, \ie, bugs introduced by translation. Even outside
of such restrictive domains, it is important to trust that the translator
faithfully translates source code; otherwise, our systems are all subject to
vicious attack~\cite{Thompson_1984}. Thus a verified translator is an important
component in the software-development tool-chain. Verifying a translator amounts
to both a proof about a particular program---the translator itself---\emph{and}
a proof about a \emph{class} of programs---those accepted and generated by the
translator. A verified translator must preserve proofs about the source; that
is, if a program \(S\) is proven to have some property \(P\) (written \(S
\models P\) after~\cite{Leroy-Compcert-CACM}), translating with a verified
translator \(\func{Compiler}\) should imply that \(\func{Compiler}(S) \models
P\). Thus we have a statement about an entire class of programs, and it is this
type of statement that allows the composition of proven layers to be proven.

Item~\ref{i:stack_asm} is particularly interesting when the machine-code was
generated without a verified translator; in this case, the programmer has no
guarantees that the translation correctly and semantically matches the original.
This has generated much work on translation validation~\cite{Pnueli_1998}, which
proceeds by validating each run of a translator, comparing the executable code
to the source and guaranteeing that a \emph{particular} set of executable code
implements a \emph{particular} set of program source code. This stands in
contrast to verified-translator proofs, which need to cover an entire class of
programs. We will have only slightly more to say on this subject when we get to
verified translators; we point the interested reader to works such
as~\cite{Sewell:phd,Sewell_KH_16,Sewell_2013,Necula_2000}.

Items~\ref{i:stack_OS} and~\ref{i:stack_hardware} are out of scope for this
report. We refer the interested reader to research on verified \gls{os} and
kernels~\cite{Klein_EHACDEEKNSTW_09,Klein_AEHCDEEKNSTW_10,Klein_AEMSKH_14,Sewell_KH_16,Narayanan_2019,Narayan_2020,Nelson_2017}
and on verifying
processors~\cite{sturton-memocode13,Sturton_2013,Bradfield_2016,zhang2017identifying,zhang2018recursive,zhang2018end}.

\subsection{Structure of this report}

In Section~\ref{S:categories} we propose to classify the tools used to verify
programs. In Section~\ref{S:examples} we look at a few examples of verified
programs and identify a few prominent strategies and challenges. In
Section~\ref{S:discussion} we discuss the frontier of the formal-methods and
verified programs research, attempting to answer the question ``What are the
next big challenges to tackle for program verification?'' Finally, we conclude
with Section~\ref{S:conclusion}.
